{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import random\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    \"\"\"\n",
    "    Sets the random seed for reproducibility.\n",
    "    Args:\n",
    "        seed (int): The seed value to set.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Using GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:2\")\n",
    "    print(\"CUDA is available. Using GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CUDA is not available. Using CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 30/30 [02:42<00:00,  5.40s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import dpkt\n",
    "import socket\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from FlowPic.sessions_plotter import session_2d_histogram  # Assuming FlowPic import\n",
    "from tqdm import tqdm  # Progress bar\n",
    "from pathlib import Path\n",
    "\n",
    "MTU = 1500  # Maximum Transmission Unit (packet size limit)\n",
    "DELTA_T = 60  # Time interval for splitting sessions\n",
    "TPS = 60  # Time per session\n",
    "MIN_TPS = 50  # Minimum time per session to consider\n",
    "\n",
    "# Multi-label list\n",
    "LABELS = [\"netflix\", \"youtube\", \"rdp\", \"rsync\", \"scp\", \"sftp\", \"skype-chat\", \"ssh\", \"vimeo\", \"voip\"]\n",
    "\n",
    "class FlowPicDataset(Dataset):\n",
    "    def __init__(self, pcap_dir, cache_dir=None):\n",
    "        \"\"\"\n",
    "        Initialize the dataset with a directory of PCAP files. It reads and stores session data.\n",
    "        Args:\n",
    "            pcap_dir (str): Path to the directory containing PCAP files.\n",
    "            cache_dir (str): Path to directory where cached .npz files are stored.\n",
    "        \"\"\"\n",
    "        self.pcap_files = glob.glob(os.path.join(pcap_dir, \"*.pcap\"))[:30]\n",
    "        self.Xs = []\n",
    "        self.ys = []\n",
    "        \n",
    "        if not cache_dir:\n",
    "            cache_dir = Path(pcap_dir) / 'flowpic_cache'\n",
    "        self.cache_dir = Path(cache_dir)\n",
    "        self.cache_dir.mkdir(exist_ok=True)  # Create cache directory if it doesn't exist\n",
    "\n",
    "        # Process each PCAP file in the directory\n",
    "        for pcap_file in tqdm(list(self.pcap_files)):\n",
    "            cache_file = self.cache_dir / f\"{Path(pcap_file).stem}.npz\"  # Use the file name without an extension\n",
    "            cache_npz_file = f\"{cache_file}.npz\"\n",
    "\n",
    "            if os.path.exists(cache_file):\n",
    "                # Load from cache if available\n",
    "                cached_data = np.load(cache_file, allow_pickle=True)\n",
    "                for d in cached_data['Xs']:\n",
    "                    sparse_tensor = torch.sparse_coo_tensor(d['indices'], d['values'], d['size'])\n",
    "                    self.Xs.append(sparse_tensor.to_dense().numpy())  # Convert to dense numpy array\n",
    "                self.ys.extend(cached_data['ys'])\n",
    "            else:\n",
    "                print(f\"{cache_file} does not exist, creating it...\")\n",
    "                label = self.extract_label(pcap_file)\n",
    "                sessions = self.parse_pcap(pcap_file)\n",
    "                dataset = self.sessions_to_flowpic(sessions)\n",
    "\n",
    "                Xs, ys = [], []\n",
    "                for flowpic in dataset:\n",
    "                    Xs.append(self.to_sparse_dict(flowpic))\n",
    "                    ys.append(label)\n",
    "\n",
    "                # Save processed data to cache\n",
    "                np.savez(cache_npz_file, Xs=Xs, ys=np.array(ys, dtype=object))\n",
    "\n",
    "                # Rename the file to remove \".npz\" suffix\n",
    "                os.rename(cache_npz_file, cache_file)\n",
    "\n",
    "                # Append FlowPic and labels to dataset\n",
    "                for d in Xs:\n",
    "                    sparse_tensor = torch.sparse_coo_tensor(d['indices'], d['values'], d['size'])\n",
    "                    self.Xs.append(sparse_tensor.to_dense().numpy())  # Convert to dense numpy array\n",
    "                self.ys.extend(ys)\n",
    "\n",
    "    def extract_label(self, file_path):\n",
    "        \"\"\"\n",
    "        Extract the multi-label based on the file name.\n",
    "        Args:\n",
    "            file_path (str): Path to the pcap file.\n",
    "        Returns:\n",
    "            label (list): Binary list corresponding to LABELS.\n",
    "        \"\"\"\n",
    "        label = [0] * len(LABELS)\n",
    "        for i, l in enumerate(LABELS):\n",
    "            if l in file_path.lower():\n",
    "                label[i] = 1\n",
    "        return label\n",
    "\n",
    "    def parse_pcap(self, pcap_path):\n",
    "        \"\"\"\n",
    "        Parse a pcap file assuming raw IP packets (no Ethernet headers).\n",
    "        Each session is a tuple of (session_key, [timestamps], [sizes]).\n",
    "        \"\"\"\n",
    "        sessions = {}\n",
    "        total_packets = 0\n",
    "        non_ip_packets = 0\n",
    "        non_tcp_udp_packets = 0\n",
    "        protocol_counts = {}\n",
    "\n",
    "        with open(pcap_path, 'rb') as f:\n",
    "            pcap = dpkt.pcap.Reader(f)\n",
    "            for ts, packet in pcap:\n",
    "                total_packets += 1\n",
    "\n",
    "                try:\n",
    "                    ip = dpkt.ip.IP(packet)  # Directly treat the packet as an IP packet\n",
    "                except dpkt.UnpackError:\n",
    "                    non_ip_packets += 1\n",
    "                    continue  # Skip if it's not a valid IP packet\n",
    "\n",
    "                proto = ip.data\n",
    "                proto_name = type(proto).__name__\n",
    "                protocol_counts[proto_name] = protocol_counts.get(proto_name, 0) + 1\n",
    "\n",
    "                if not isinstance(proto, (dpkt.tcp.TCP, dpkt.udp.UDP)):\n",
    "                    non_tcp_udp_packets += 1\n",
    "                    continue  # Only TCP and UDP are handled\n",
    "\n",
    "                session_key = (socket.inet_ntoa(ip.src), proto.sport, socket.inet_ntoa(ip.dst), proto.dport, proto_name)\n",
    "                if session_key not in sessions:\n",
    "                    sessions[session_key] = (ts, [], [])\n",
    "\n",
    "                d = sessions[session_key]\n",
    "                size = len(ip)  # Packet size\n",
    "                d[1].append(ts - d[0])  # Time delta\n",
    "                d[2].append(size)  # Packet size\n",
    "\n",
    "        return sessions\n",
    "\n",
    "    def sessions_to_flowpic(self, sessions):\n",
    "        \"\"\"\n",
    "        Convert session data to FlowPic format.\n",
    "        \"\"\"\n",
    "        dataset = []\n",
    "        for session_key, (start_ts, ts_list, sizes) in sessions.items():\n",
    "            ts = np.array(ts_list)\n",
    "            sizes = np.array(sizes)\n",
    "\n",
    "            if len(ts) > 1:  # Consider sessions with at least 2 packets\n",
    "                for t in range(int(ts[-1] / DELTA_T - TPS / DELTA_T) + 1):\n",
    "                    mask = (ts >= t * DELTA_T) & (ts <= (t * DELTA_T + TPS))\n",
    "                    ts_mask = ts[mask]\n",
    "                    sizes_mask = sizes[mask]\n",
    "\n",
    "                    if len(ts_mask) > 1:  # Adjust packet count check here\n",
    "                        h = session_2d_histogram(ts_mask, sizes_mask)\n",
    "                        dataset.append(h)\n",
    "\n",
    "        return dataset\n",
    "\n",
    "    def to_sparse_dict(self, flowpic):\n",
    "        \"\"\"\n",
    "        Convert a dense FlowPic matrix to a dictionary of sparse representation (indices, values, size).\n",
    "        \"\"\"\n",
    "        flowpic = np.array(flowpic, dtype=np.float32)\n",
    "        indices = np.nonzero(flowpic)\n",
    "        values = flowpic[indices]\n",
    "        size = flowpic.shape\n",
    "        return {'indices': np.array(indices), 'values': values, 'size': size}\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Return the total number of FlowPic samples in the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.Xs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Return the FlowPic representation of a session along with its label.\n",
    "        \"\"\"\n",
    "        flowpic, label = self.Xs[idx], self.ys[idx]\n",
    "        \n",
    "        # Ensure the flowpic is a numpy array of type float32 before converting to tensor\n",
    "        flowpic = np.array(flowpic, dtype=np.float32)\n",
    "        label = np.array(label, dtype=np.float32)\n",
    "        \n",
    "        return torch.tensor(flowpic), torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "\n",
    "# Helper function to create DataLoader\n",
    "def create_dataloader(pcap_dir, batch_size=32, shuffle=True, num_workers=4, cache_dir=None):\n",
    "    \"\"\"\n",
    "    Create a DataLoader for FlowPicDataset.\n",
    "    Args:\n",
    "        pcap_dir (str): Path to the directory containing PCAP files.\n",
    "        batch_size (int): Number of samples per batch.\n",
    "        shuffle (bool): Whether to shuffle the data.\n",
    "        num_workers (int): Number of subprocesses to use for data loading.\n",
    "        cache_dir (str): Directory where cached .npy files are stored.\n",
    "    \"\"\"\n",
    "    dataset = FlowPicDataset(pcap_dir, cache_dir=cache_dir)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "# Example usage\n",
    "pcap_dir = Path('/home/anatbr/students/noamshakedc/da4etc/data/vpnnonvpn')  # Path to your PCAP directory\n",
    "dataloader = create_dataloader(pcap_dir, batch_size=16)\n",
    "\n",
    "# Iterate over the data\n",
    "labelss = []\n",
    "for batch, labels in dataloader:\n",
    "    labelss.append(labels)\n",
    "    if len(labelss) > 5:\n",
    "        break\n",
    "    # print(f\"Batch shape: {batch.shape}, Labels: {labels}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "# Number of classes based on the LABELS list\n",
    "num_classes = len(LABELS)  # This will be the output size of the model\n",
    "learning_rate = 1e-3\n",
    "\n",
    "class TrafficCNN(nn.Module):\n",
    "    def __init__(self, num_classes=num_classes):\n",
    "        super(TrafficCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=10, stride=5, padding=1)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=10, stride=5, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(20 * 15 * 15, 64)  # Adjust the dimensions if needed\n",
    "        self.fc2 = nn.Linear(64, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 20 * 15 * 15)  # Flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)  # Multi-class classification\n",
    "\n",
    "# Create train and validation split\n",
    "# dataset = FlowPicDataset(pcap_dir)  # Assuming this is your dataset\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=4)\n",
    "\n",
    "# Model initialization\n",
    "model = TrafficCNN(num_classes=num_classes)\n",
    "\n",
    "# Optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()  # For multi-class classification\n",
    "\n",
    "# Training loop\n",
    "def train(model, train_loader, val_loader, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs.unsqueeze(1))  # Add channel dimension for Conv2D\n",
    "            loss = criterion(outputs, torch.argmax(labels, dim=1))  # CrossEntropyLoss expects class indices, not one-hot\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        print(f'Epoch {epoch+1}, Loss: {running_loss / len(train_loader)}')\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                outputs = model(inputs.unsqueeze(1))  # Add channel dimension for Conv2D\n",
    "                loss = criterion(outputs, torch.argmax(labels, dim=1))\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == torch.argmax(labels, dim=1)).sum().item()\n",
    "\n",
    "        print(f'Validation Loss: {val_loss / len(val_loader)}, Accuracy: {100 * correct / total}%')\n",
    "\n",
    "# Running the training\n",
    "train(model, train_loader, val_loader, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define the structure and file contents based on the notebook\n",
    "flowpic_dir = 'FlowPic'\n",
    "\n",
    "# Ensure the directory for FlowPic exists\n",
    "os.makedirs(flowpic_dir, exist_ok=True)\n",
    "\n",
    "# Split the code into different files and modules for a Python package structure\n",
    "# File: FlowPic/utils.py (contains set_seed and device setup)\n",
    "\n",
    "utils_py = \"\"\"\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def set_seed(seed):\n",
    "    \\\"\\\"\\\"\n",
    "    Sets the random seed for reproducibility.\n",
    "    Args:\n",
    "        seed (int): The seed value to set.\n",
    "    \\\"\\\"\\\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda:2\")\n",
    "        print(\"CUDA is available. Using GPU\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"CUDA is not available. Using CPU.\")\n",
    "    return device\n",
    "\"\"\"\n",
    "\n",
    "with open(os.path.join(flowpic_dir, 'utils.py'), 'w') as f:\n",
    "    f.write(utils_py)\n",
    "\n",
    "# File: FlowPic/model.py (contains model definition)\n",
    "\n",
    "model_py = \"\"\"\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FlowPicCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(FlowPicCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 37 * 37, 128)  # Adjust based on input image size\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 37 * 37)  # Flatten the tensor\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\"\"\"\n",
    "\n",
    "with open(os.path.join(flowpic_dir, 'model.py'), 'w') as f:\n",
    "    f.write(model_py)\n",
    "\n",
    "# File: FlowPic/train.py (contains training and validation logic)\n",
    "\n",
    "train_py = \"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "def train(model, train_loader, val_loader, num_epochs, device):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs.unsqueeze(1))  # Add channel dimension for Conv2D\n",
    "            loss = criterion(outputs, torch.argmax(labels, dim=1))  # CrossEntropyLoss expects class indices\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f'Epoch {epoch+1}, Loss: {running_loss / len(train_loader)}')\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs.unsqueeze(1))  # Add channel dimension for Conv2D\n",
    "                loss = criterion(outputs, torch.argmax(labels, dim=1))\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == torch.argmax(labels, dim=1)).sum().item()\n",
    "\n",
    "        print(f'Validation Loss: {val_loss / len(val_loader)}, Accuracy: {100 * correct / total}%')\n",
    "\"\"\"\n",
    "\n",
    "with open(os.path.join(flowpic_dir, 'train.py'), 'w') as f:\n",
    "    f.write(train_py)\n",
    "\n",
    "# Main script: main.py\n",
    "\n",
    "main_py = \"\"\"\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from FlowPic.utils import set_seed, get_device\n",
    "from FlowPic.model import FlowPicCNN\n",
    "from FlowPic.train import train\n",
    "\n",
    "def main():\n",
    "    # Set the seed\n",
    "    set_seed(42)\n",
    "\n",
    "    # Get the device (GPU or CPU)\n",
    "    device = get_device()\n",
    "\n",
    "    # Assuming data is loaded somewhere here (train_loader, val_loader)\n",
    "    # Example:\n",
    "    # train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    # val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "\n",
    "    # Initialize the model and move it to the device\n",
    "    num_classes = 10  # Adjust based on your problem\n",
    "    model = FlowPicCNN(num_classes).to(device)\n",
    "\n",
    "    # Run training\n",
    "    num_epochs = 10  # Adjust as needed\n",
    "    train(model, train_loader, val_loader, num_epochs, device)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\"\"\"\n",
    "\n",
    "# Save the main.py file\n",
    "with open('main.py', 'w') as f:\n",
    "    f.write(main_py)\n",
    "\n",
    "# Notify the user that files are created\n",
    "\"Files have been successfully created in the FlowPic directory and main.py.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml1",
   "language": "python",
   "name": "ml1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
